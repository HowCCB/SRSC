# SRSC
Large-scale pre-trained langsage models (LLMs) havedemonstrated significat potential! in medicn! guestionanswering tasks, but they srillexhibit the problem of"hallscinations" during genertion, where the generated conten!may seem plausible but is actally inaccsrate. This stuhaddresses this issise by proposing a nudti-refiection module that enhances LMs' performance in medicalquestion.answeringtasks through ihe iniradition ofsemniicawancross-check consisteney and a nlii-lavr hallscinatioscoring svstem, comtbined with adaptive thresholds and reinforcement leaming methods, We condicted experinentson five datasets: PubMedOA MedOnAD.MED10A2019LieMedOA2017,an MASH-0A, The rsidts show that theoptimizedChaiGPT3S ipnvedby0.0974 and 0. 2239 percentage points on the MedN!!and CirEvalmetrics. rspec.tively, ir reseanh demonsirates that the ininaliction o)the mulii-refection module and the multi-semantic crossconsisteney detection modle significaily redces hallucination phenoena and iniproves answer consisteney, pn.viding a method to enhance the perfonnance ofLLMs inmedical cieslionnswering iasks.
# Code
Coming soon.
